{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headlines for the search query: Sports yesterday\n",
      "1. Today's Top Sports Scores and Games (All Sports)\n",
      "2. Latest Sports News\n",
      "3. Yahoo Sports: News, Scores, Video, Fantasy Games ...\n",
      "4. FOX Sports News, Scores, Schedules, Odds, Shows, Streams ...\n",
      "5. Latest sports news, videos, interviews and comment\n",
      "6. Sport Scores, Stats and Highlights\n",
      "7. Sports News, Scores, Predictions and Analysis - USA TODAY\n",
      "8. All Sports Scoreboard\n",
      "9. CBS Sports - News, Live Scores, Schedules, Fantasy Games ...\n",
      "10. More results\n",
      "11. Try again\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# google search headline scraper\n",
    "def scrape_google_headlines(query):\n",
    "    url = f\"https://www.google.com/search?q={query}&hl=en\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        headlines = []\n",
    "        for headline in soup.find_all('h3'):\n",
    "            headlines.append(headline.text)\n",
    "        return headlines\n",
    "    else:\n",
    "        print(\"Failed to retrieve search results.\")\n",
    "        return []\n",
    "\n",
    "query = \"Sports yesterday\"\n",
    "headlines = scrape_google_headlines(query)\n",
    "if headlines:\n",
    "    print(\"Headlines for the search query:\", query)\n",
    "    for idx, headline in enumerate(headlines, 1):\n",
    "        print(f\"{idx}. {headline}\")\n",
    "else:\n",
    "    print(\"No headlines found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_yesterday(date_string):\n",
    "    # Define the format of the input date string without the timezone part\n",
    "    date_format = '%B %d, %Y, %I:%M %p ET'\n",
    "    \n",
    "    # Parse the date string into a naive datetime object\n",
    "    naive_date_time = datetime.strptime(date_string, date_format)\n",
    "    \n",
    "    # Define the timezone (Eastern Time)\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    \n",
    "    # Localize the naive datetime to Eastern Time\n",
    "    eastern_date_time = eastern.localize(naive_date_time)\n",
    "    \n",
    "    # Get the current date and time in Eastern Time\n",
    "    now_eastern = datetime.now(pytz.timezone('US/Eastern'))\n",
    "    \n",
    "    # Calculate the date for yesterday in Eastern Time\n",
    "    yesterday_eastern = now_eastern - timedelta(days=1)\n",
    "    \n",
    "    # Check if the date is exactly yesterday (ignoring time)\n",
    "    return eastern_date_time.date() == yesterday_eastern.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://www.espn.com/espn/latestnews\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "response = requests.get(url, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = soup.find(class_=\"span-4\")\n",
    "sports = articles.find_all('h3')\n",
    "sport_headlines_dict = {}\n",
    "for sport in sports:\n",
    "    sport = sport.text\n",
    "    sport_headlines = soup.find('h3', string=sport).find_next_sibling().find_all('li')\n",
    "    sport_headlines_dict[sport] = []\n",
    "    for headline in sport_headlines:\n",
    "        htext = headline.get_text(strip=True)\n",
    "        title = htext[0:htext.rfind('(')]\n",
    "        date = htext[htext.rfind('(')+1:-1]\n",
    "        if is_yesterday(date):\n",
    "            sport_headlines_dict[sport].append(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is good, but I think im scraping wrong thing, headlines may not be the way to go, maybe read the top article for each in season sport on ESPN homepage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
